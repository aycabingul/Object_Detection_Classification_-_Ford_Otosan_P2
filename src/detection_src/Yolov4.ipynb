{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Yolov4.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ecW467fbNc4N"
      },
      "source": [
        "# YOLOV4 OBJECT DETECTION"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_TEYbG1yNTFd"
      },
      "source": [
        "### STEP 1: DARKNET CLONE AND INSTALLATION"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ny1G-RZtG4Na"
      },
      "source": [
        "#!unzip -d /content/drive/MyDrive /content/drive/MyDrive/yolov4.zip"
      ],
      "execution_count": 46,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kHYXSr5cDHDD"
      },
      "source": [
        "#!zip -r /content/gdrive/MyDrive/yolov4.zip /content/gdrive/MyDrive/yolov4"
      ],
      "execution_count": 47,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mDaCPqPPMtI5"
      },
      "source": [
        "# clone darknet repo\n",
        "!git clone https://github.com/AlexeyAB/darknet"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HZjRJqIjzupb"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sn6ant8qNlYA"
      },
      "source": [
        "# change makefile to have GPU and OPENCV enabled\n",
        "%cd darknet\n",
        "!sed -i 's/OPENCV=0/OPENCV=1/' Makefile  #I will use opencv library in darknet\n",
        "!sed -i 's/GPU=0/GPU=1/' Makefile #I will use cpu library in darknet\n",
        "!sed -i 's/CUDNN=0/CUDNN=1/' Makefile #cudnn a necessary tool for cpu\n",
        "!sed -i 's/CUDNN_HALF=0/CUDNN_HALF=1/' Makefile"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zHsCoQi7OX13"
      },
      "source": [
        "# verify CUDA\n",
        "!/usr/local/cuda/bin/nvcc --version"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UALaKDuxOhGW"
      },
      "source": [
        "# make darknet (builds darknet so that you can then use the darknet executable file to run or train object detectors)\n",
        "!make"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uqbEp31ViBMY"
      },
      "source": [
        "### STEP 2: LOADING THE DATASET WE HAVE PREPARED"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8Af3q0t-hwnP"
      },
      "source": [
        "# this is where my datasets are stored within my Google Drive (I created a yolov4 folder to store all important files for custom training) \n",
        "#%cd darknet/\n",
        "!ls /content/drive/MyDrive/yolov4"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1M8yiG9Di6yF"
      },
      "source": [
        "# copy over both datasets into the root directory of the Colab VM (comment out test.zip if you are not using a validation dataset)\n",
        "!cp /content/drive/MyDrive/yolov4/obj.zip ../\n",
        "!cp /content/drive/MyDrive/yolov4/test.zip ../"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tfaT3dPDi-FP"
      },
      "source": [
        "# unzip the datasets and their contents so that they are now in /darknet/data/ folder\n",
        "!unzip ../obj.zip -d data/\n",
        "!unzip ../test.zip -d data/"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JjUwQnxEkY5g"
      },
      "source": [
        "### **STEP 3: LET'S PREPARE THE REQUIRED FILES FOR THE TRAINING**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MHC8aFRXjGm8"
      },
      "source": [
        "In this step, we will create the .cfg file, obj.data, obj.names and train.txt files required for the training."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VvJu1fzCztYO"
      },
      "source": [
        "download cfg to google drive and change its name                         \n",
        "```\n",
        "from shutil import copy2                                    \n",
        "copy2(\"/content/darknet/cfg/yolov4-custom.cfg\",\"/content/drive/MyDrive/yolov4\")    \n",
        "```      \n",
        "you can also copy like this\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hOR3wPTUyiSQ"
      },
      "source": [
        "# download cfg to google drive and change its name\n",
        "#%cd darknet/\n",
        "#!cp cfg/yolov4-custom.cfg /content/drive/MyDrive/yolov4/yolov4-obj.cfg"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "N2AJgJeX1d2j"
      },
      "source": [
        "Changes we need to make in our config file:\n",
        "\n",
        "(The values given here are the recommended values for these variables.)\n",
        "\n",
        "1. The batch value in our config file is the number of images we will import into our convolutional neural network in each iteration. Subdivision determines how many subdivisions we will divide each batch into. We can set the subdivision value to 16. **batch = 64 and subdivision 16.**\n",
        "\n",
        "2. Then we can change the image size that will enter the model from the width and height sections. The max_batches value determines how many iterations our model will take. We can set our class number to *2000. Since we will train a model consisting of one class, we set the Max_batches value to 6000. We equalize max_batches(2000 * number of classes trained). But the minimum we can do is 6000, so if you have one, two and three classes, it should be 6000.\n",
        "\n",
        "3. Then we change the value of the step to 80% or 90% of our max_batches value. I set the value of the step to 4800 which is 80% of 6000. **We make the values of the steps (80% of max_batches), (90% of max_batches).**\n",
        "\n",
        "4. We replace the classes values under the [yolo] heading with the number of classes we train.\n",
        "\n",
        "5. The Steps parameter is the number of iterations that the learning rate will be reduced to fit our model well. Finally, in our config file, we set the value of the class parameters to 3, which is our class number. We change the Filters parameters to (class + 5) * 3. In our case, this value is 18. We also equalize the filter's variables (number of classes to train + 5 )*3."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oK1a9dCIyiuf"
      },
      "source": [
        "# upload the custom .cfg back to cloud VM from Google Drive\n",
        "\n",
        "!cp /content/drive/MyDrive/yolov4/yolov4-obj.cfg ./cfg"
      ],
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8cInjxJm7GpZ"
      },
      "source": [
        "**-obj.names and obj.data**\n",
        "\n",
        "Let's create a file named obj.names in our folder named yolov3 and write the names of your objects that we will train the file with.\n",
        "\n",
        "E.G:\n",
        "```\n",
        "traffic sign\n",
        "traffic light\n",
        "```\n",
        "\n",
        "In the same folder, we create a file with the name obj.data and write the directory where we will save the number of objects we will train, the addresses of the files named train.txt, text.txt and obj.names that we will use while training, and the weights we find as a result of the training.\n",
        "\n",
        "E.G:\n",
        "```\n",
        "classes = 1\n",
        "train = data/train.txt\n",
        "valid = data/test.txt\n",
        "names = data/obj.names\n",
        "backup = /mydrive/yolov4/backup\n",
        "```\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gVQZjKcL95vl"
      },
      "source": [
        "upload the obj.names and obj.data files to cloud VM from Google Drive"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "c6-M5rFK7HN1"
      },
      "source": [
        "!cp /content/drive/MyDrive/yolov4/obj.names ./data\n",
        "!cp /content/drive/MyDrive/yolov4/obj.data  ./data"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IBr35ggE-AZq"
      },
      "source": [
        "#### **-Train and Test Files**\n",
        "\n",
        "\n",
        "**generate_train.py**\n",
        "\n",
        "\n",
        "\n",
        "```\n",
        "  import os\n",
        "  image_files = []\n",
        "  os.chdir(os.path.join(\"data\", \"obj\"))\n",
        "  for filename in os.listdir(os.getcwd()):\n",
        "      if filename.endswith(\".jpg\"):\n",
        "          image_files.append(\"data/obj/\" + filename)\n",
        "  os.chdir(\"..\")\n",
        "  with open(\"train.txt\", \"w\") as outfile:\n",
        "      for image in image_files:\n",
        "          outfile.write(image)\n",
        "          outfile.write(\"\\n\")\n",
        "      outfile.close()\n",
        "  os.chdir(\"..\")\n",
        "```\n",
        "\n",
        "**generate_test.py**\n",
        "\n",
        "\n",
        "\n",
        "```\n",
        "  import os\n",
        "\n",
        "  image_files = []\n",
        "  os.chdir(os.path.join(\"data\", \"test\"))\n",
        "  for filename in os.listdir(os.getcwd()):\n",
        "      if filename.endswith(\".jpg\"):\n",
        "          image_files.append(\"data/test/\" + filename)\n",
        "  os.chdir(\"..\")\n",
        "  with open(\"test.txt\", \"w\") as outfile:\n",
        "      for image in image_files:\n",
        "          outfile.write(image)\n",
        "          outfile.write(\"\\n\")\n",
        "      outfile.close()\n",
        "  os.chdir(\"..\")\n",
        "```\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "m5qJ748-TutK"
      },
      "source": [
        "upload the generate_train.py and generate_test.py script to cloud VM from Google Drive\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ec8OtGiW-Ety"
      },
      "source": [
        "!cp /content/drive/MyDrive/yolov4/generate_train.py ./\n",
        "!cp /content/drive/MyDrive/yolov4/generate_test.py ./"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bMF6d35sUC-4"
      },
      "source": [
        "!python generate_train.py\n",
        "!python generate_test.py"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GrKi1gUQUDeE"
      },
      "source": [
        "# verify that the newly generated train.txt and test.txt can be seen in our darknet/data folder\n",
        "!ls data/"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bZPKhQgqVFAF"
      },
      "source": [
        "### STEP 4: REDUCE THE WEIGHTS OF PRE-TRAINED CONVOLUTIONAL LAYERS\n",
        "\n",
        "In this step, we download the used deep learning layers weights for the pre-trained yolov3. We do not have to perform this step, but starting the training with these weights will help the model we train to work more accurately and shorten the training time."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ab3ofltAVGOu"
      },
      "source": [
        "!wget https://github.com/AlexeyAB/darknet/releases/download/darknet_yolo_v3_optimal/yolov4.conv.137"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MSm93uBkVTHV"
      },
      "source": [
        "### STEP 5: TRAINING\n",
        "All the necessary files are ready, we can start the training."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "db6QZ2HVWYFY"
      },
      "source": [
        "Training will begin with the next command.\n",
        "\n",
        "The duration of our training may vary depending on factors such as the number of photos in your data set, the quality of the photos, and the number of objects you train. Our loss value is important for the accuracy of our model. The lower our Loss value, the more accurate our model will work. We can run our model until the loss value stops decreasing and train the most accurate model possible according to our data set."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qVYYLkSmViFg"
      },
      "source": [
        "# train your custom detector! (uncomment %%capture below if you run into memory issues or your Colab is crashing)\n",
        "# %%capture\n",
        "!./darknet detector train data/obj.data cfg/yolov4-obj.cfg yolov4.conv.137 -dont_show -map"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MTv7nvWPWoL1"
      },
      "source": [
        "# the graph of our training.\n",
        "imShow('chart.png')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fIXX6trKW_Gm"
      },
      "source": [
        "If we don't like the weights, we can continue the training from where we left off."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pe0R7MNJW-lF"
      },
      "source": [
        "!./darknet detector train data/obj.data cfg/yolov4-obj.cfg /content/drive/MyDrive/yolov4/backup/yolov4-obj_last.weights -dont_show"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "s_1meAhSyd2d"
      },
      "source": [
        "### STEP 6: USE OUR TRAINED MODEL\n",
        "\n",
        "\n",
        "Our training is complete, now we can make recognition on the photos we want."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lyJzvhv4X48Z"
      },
      "source": [
        "Let's look at the average loss value and percent accuracy of our model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "630qDfB3ydff"
      },
      "source": [
        "!./darknet detector map data/obj.data cfg/yolov4-obj.cfg /content/drive/MyDrive/yolov4/backup/yolov4-obj_last.weights"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gG-MtCljyiwG"
      },
      "source": [
        "#### **Let's run our model**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KatbNMnfRoh0"
      },
      "source": [
        "# define helper functions\n",
        "def imShow(path): \n",
        "  import cv2\n",
        "  import matplotlib.pyplot as plt\n",
        "  %matplotlib inline\n",
        "\n",
        "  image = cv2.imread(path)\n",
        "  height, width = image.shape[:2]\n",
        "  resized_image = cv2.resize(image,(3*width, 3*height), interpolation = cv2.INTER_CUBIC)\n",
        "\n",
        "  fig = plt.gcf()\n",
        "  fig.set_size_inches(18, 10)\n",
        "  plt.axis(\"off\")\n",
        "  plt.imshow(cv2.cvtColor(resized_image, cv2.COLOR_BGR2RGB))\n",
        "  plt.show()\n",
        "\n",
        "# use this to upload files\n",
        "def upload():\n",
        "  from google.colab import files\n",
        "  uploaded = files.upload() \n",
        "  for name, data in uploaded.items():\n",
        "    with open(name, 'wb') as f:\n",
        "      f.write(data)\n",
        "      print ('saved file', name)\n",
        "\n",
        "# use this to download a file  \n",
        "def download(path):\n",
        "  from google.colab import files\n",
        "  files.download(path)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-lj-UAi4yp_c"
      },
      "source": [
        "# need to set our custom cfg to test mode \n",
        "%cd cfg\n",
        "!sed -i 's/batch=64/batch=1/' yolov4-obj.cfg\n",
        "!sed -i 's/subdivisions=16/subdivisions=1/' yolov4-obj.cfg\n",
        "%cd .."
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Yh1CnruZVk4w"
      },
      "source": [
        "To predict and see individual images"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rmOCrrdjysOR"
      },
      "source": [
        "# run your custom detector with this command (upload an image to your google drive to test, thresh flag sets accuracy that detection must be in order to show it)\n",
        "!./darknet detector test data/obj.data cfg/yolov4-obj.cfg /content/drive/MyDrive/yolov4/backup/yolov4-obj_last.weights /content/drive/MyDrive/images/cfc_000311.jpg -thresh 0.3\n",
        "imShow('predictions.jpg')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RX-UOg0-YBfU"
      },
      "source": [
        "### **STEP 7: PREDICTION WITH TEST DATASET**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XvDACYmMVvjM"
      },
      "source": [
        "**To predict and save multiple images**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_WAABvvFLh5Q"
      },
      "source": [
        "cp /content/drive/MyDrive/yolov4/test_pred.zip ../"
      ],
      "execution_count": 60,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zR7_0BpGeIrl"
      },
      "source": [
        "!unzip /content/test_pred.zip "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ts7JfnG2g_Cy"
      },
      "source": [
        "%cd /content/darknet/"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "K9USp054fwIw"
      },
      "source": [
        "# need to set our custom cfg to test mode \n",
        "%cd cfg\n",
        "!sed -i 's/batch=64/batch=1/' yolov4-obj.cfg\n",
        "!sed -i 's/subdivisions=16/subdivisions=1/' yolov4-obj.cfg\n",
        "%cd .."
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5GiFgH6jEs3R"
      },
      "source": [
        "!cp /content/drive/MyDrive/yolov4/backup/yolov4-obj_last.weights ../"
      ],
      "execution_count": 64,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "deZsUdQMNsm_"
      },
      "source": [
        "import glob\n",
        "import os\n",
        "image_path=\"../test_pred\"\n",
        "image_path_list = glob.glob(os.path.join(image_path, '*'))\n",
        "image_path_list.sort()\n"
      ],
      "execution_count": 37,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZmFKa5fSWJkS"
      },
      "source": [
        "\n",
        "def detectionPredict(imageDir):\n",
        "    import glob\n",
        "    import os\n",
        "    import cv2\n",
        "    os.system(\"./darknet detector test data/obj.data cfg/yolov4-obj.cfg ../yolov4-obj_last.weights {} -thresh 0.3\".format(imageDir))\n",
        "\n",
        "  "
      ],
      "execution_count": 38,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "glgDDvrOLOU2",
        "outputId": "7c8a4db2-8e18-4881-9ed3-3de32c5347f3"
      },
      "source": [
        "#import torch.nn as nn\n",
        "#import torch.optim as optim\n",
        "from constant import *\n",
        "import tqdm\n",
        "import torch\n",
        "from preprocessing import tensorize_image, tensorize_mask, image_mask_check\n",
        "import cv2\n",
        "from train import *\n",
        "from PIL import Image\n",
        "\n",
        "\n",
        "\n",
        "model_freespace= torch.load('/content/drive/MyDrive/models/Unet_1.pt')\n",
        "\n",
        "model_line=torch.load('/content/drive/MyDrive/models/best_line_model.pt',map_location='cuda:0')\n",
        "model_freespace=model_freespace.eval()\n",
        "model_line=model_line.eval()\n",
        "input_shape=(224,224)\n",
        "cuda=True\n",
        "if cuda:\n",
        "    model_line = model_line.cuda()\n",
        "    model_freespace=model_freespace.cuda()\n",
        "\n",
        "\n",
        "for i in tqdm.tqdm(range(len(image_path_list))):\n",
        "    batch_test = image_path_list[i:i+1]\n",
        "    test_input_line = tensorize_image(batch_test, input_shape, cuda)\n",
        "    test_input_freespace=tensorize_image(batch_test, input_shape, cuda)\n",
        "    outs_freespace = model_freespace(test_input_freespace)\n",
        "    outs_line = model_line(test_input_line)\n",
        "    out_freespace=torch.argmax(outs_freespace,axis=1)\n",
        "    out_line=torch.argmax(outs_line,axis=1)\n",
        "    out_freespace_cpu = out_freespace.cpu()\n",
        "    out_line_cpu=out_line.cpu()\n",
        "    outputs_list_freespace=out_freespace_cpu.detach().numpy()\n",
        "    outputs_list_line=out_line_cpu.detach().numpy()\n",
        "    mask_freespace=np.squeeze(outputs_list_freespace,axis=0)\n",
        "    mask_line=np.squeeze(outputs_list_line,axis=0)\n",
        "    mask_uint8_line = mask_line.astype('uint8')\n",
        "    mask_uint8_freespace = mask_freespace.astype('uint8')\n",
        "    mask_line= cv2.resize(mask_uint8_line, (1920, 1208),interpolation=cv2.INTER_NEAREST)\n",
        "    mask_freespace= cv2.resize(mask_uint8_freespace, (1920, 1208),interpolation=cv2.INTER_CUBIC)\n",
        "        \n",
        "    detectionPredict(batch_test[0])\n",
        "    \n",
        "    img=cv2.imread(\"predictions.jpg\")\n",
        " \n",
        "    mask_ind   = mask_line == 1\n",
        "    mask_ind   = mask_freespace == 1\n",
        "    cpy_img  = img.copy()\n",
        "    \n",
        "    img[mask_freespace==1,:] = (255, 0, 125)\n",
        "\n",
        "\n",
        "    img[mask_line==1,:]=(0, 0, 255)\n",
        "    img[mask_line==2,:]=(38, 255, 255)\n",
        "    \n",
        "    \n",
        "    opac_image=(img/2+cpy_img/2).astype(np.uint8)\n",
        "    predict_name=batch_test[0]\n",
        "    predict_path=predict_name.replace('test_pred', 'full_predict')\n",
        "    cv2.imwrite(predict_path,opac_image.astype(np.uint8))\n",
        "\n"
      ],
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\r  0%|          | 0/171 [00:00<?, ?it/s]/usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:718: UserWarning: Named tensors and all their associated APIs are an experimental feature and subject to change. Please do not use them for anything important until they are released as stable. (Triggered internally at  /pytorch/c10/core/TensorImpl.h:1156.)\n",
            "  return torch.max_pool2d(input, kernel_size, stride, padding, dilation, ceil_mode)\n",
            "100%|██████████| 171/171 [11:49<00:00,  4.15s/it]\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jTrAoFyQPhB_"
      },
      "source": [
        "!zip -r predict_full.zip /content/full_predict\n",
        "!cp predict_full.zip /content/drive/MyDrive/predicts"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pSjhFJeTxTsw"
      },
      "source": [
        "### **STEP 8: Sign detection in video data**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "b0qbo6GsxTBY"
      },
      "source": [
        "!./darknet detector demo data/obj.data cfg/yolov4-obj.cfg /content/drive/MyDrive/yolov4/backup/yolov4-obj_last.weights -dont_show /content/drive/MyDrive/video/videoplayback_3.mp4 -thresh 0.2 -i 0 -out_filename /content/drive/MyDrive/video/results3.avi"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}