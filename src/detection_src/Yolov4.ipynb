{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Yolov4.ipynb",
      "provenance": [],
      "collapsed_sections": [
        "IBr35ggE-AZq",
        "bZPKhQgqVFAF",
        "MSm93uBkVTHV",
        "s_1meAhSyd2d",
        "gG-MtCljyiwG",
        "PrzCzhhwZGKG",
        "RX-UOg0-YBfU",
        "pSjhFJeTxTsw"
      ]
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ecW467fbNc4N"
      },
      "source": [
        "# YOLOV4 OBJECT DETECTION"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_TEYbG1yNTFd"
      },
      "source": [
        "### STEP 1: DARKNET CLONE AND INSTALLATION"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ny1G-RZtG4Na"
      },
      "source": [
        "#!unzip -d /content/drive/MyDrive /content/drive/MyDrive/Intern2_FORD.zip"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oHrR3NJE09Nu"
      },
      "source": [
        "#!zip -r /content/drive/MyDrive/Intern2_FORD.zip /content/drive/MyDrive/Intern2_FORD"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mDaCPqPPMtI5"
      },
      "source": [
        "# clone darknet repo\n",
        "!git clone https://github.com/AlexeyAB/darknet"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HZjRJqIjzupb"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sn6ant8qNlYA"
      },
      "source": [
        "# change makefile to have GPU and OPENCV enabled\n",
        "%cd darknet\n",
        "!sed -i 's/OPENCV=0/OPENCV=1/' Makefile  #I will use opencv library in darknet\n",
        "!sed -i 's/GPU=0/GPU=1/' Makefile #I will use cpu library in darknet\n",
        "!sed -i 's/CUDNN=0/CUDNN=1/' Makefile #cudnn a necessary tool for cpu\n",
        "!sed -i 's/CUDNN_HALF=0/CUDNN_HALF=1/' Makefile"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zHsCoQi7OX13"
      },
      "source": [
        "# verify CUDA\n",
        "!/usr/local/cuda/bin/nvcc --version"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EGPBbx3FE4iR"
      },
      "source": [
        "!cp /content/drive/MyDrive/yolov4/image.c /content/darknet/src/"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UALaKDuxOhGW"
      },
      "source": [
        "# make darknet (builds darknet so that you can then use the darknet executable file to run or train object detectors)\n",
        "!make"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uqbEp31ViBMY"
      },
      "source": [
        "### STEP 2: LOADING THE DATASET WE HAVE PREPARED"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8Af3q0t-hwnP"
      },
      "source": [
        "# this is where my datasets are stored within my Google Drive (I created a yolov4 folder to store all important files for custom training) \n",
        "#%cd darknet/\n",
        "!ls /content/drive/MyDrive/yolov4"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1M8yiG9Di6yF"
      },
      "source": [
        "# copy over both datasets into the root directory of the Colab VM (comment out test.zip if you are not using a validation dataset)\n",
        "!cp /content/drive/MyDrive/yolov4/obj.zip ../\n",
        "!cp /content/drive/MyDrive/yolov4/test.zip ../"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tfaT3dPDi-FP"
      },
      "source": [
        "# unzip the datasets and their contents so that they are now in /darknet/data/ folder\n",
        "!unzip ../obj.zip -d data/\n",
        "!unzip ../test.zip -d data/"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JjUwQnxEkY5g"
      },
      "source": [
        "### **STEP 3: LET'S PREPARE THE REQUIRED FILES FOR THE TRAINING**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MHC8aFRXjGm8"
      },
      "source": [
        "In this step, we will create the .cfg file, obj.data, obj.names and train.txt files required for the training."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VvJu1fzCztYO"
      },
      "source": [
        "download cfg to google drive and change its name                         \n",
        "```\n",
        "from shutil import copy2                                    \n",
        "copy2(\"/content/darknet/cfg/yolov4-custom.cfg\",\"/content/drive/MyDrive/yolov4\")    \n",
        "```      \n",
        "you can also copy like this\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hOR3wPTUyiSQ"
      },
      "source": [
        "# download cfg to google drive and change its name\n",
        "#%cd darknet/\n",
        "#!cp cfg/yolov4-custom.cfg /content/drive/MyDrive/yolov4/yolov4-obj.cfg"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "N2AJgJeX1d2j"
      },
      "source": [
        "Changes we need to make in our config file:\n",
        "\n",
        "(The values given here are the recommended values for these variables.)\n",
        "\n",
        "1. The batch value in our config file is the number of images we will import into our convolutional neural network in each iteration. Subdivision determines how many subdivisions we will divide each batch into. We can set the subdivision value to 16. **batch = 64 and subdivision 16.** Subdivision=8 -> Split batch into 8 mini-batches so 64/8 = 8 images per mini-batch and these 8 images are sent to the GPU for processing. This process will be performed 8 times until the batch is completed and a new iteration will start with 64 new images.\n",
        "If you are using a GPU where the RAM is low, set a higher value for subdivisions ( 32 or 64). This will obviously take longer to train since we are reducing the number of images being loaded and also the number of mini-batches.\n",
        "If you have a GPU with good RAM, set a lower value for subdivisions (16 or 8). This will speed up the training process as this loads more images per iteration.\n",
        "\n",
        "2. Then we can change the image size that will enter the model from the width and height sections. The max_batches value determines how many iterations our model will take. We can set our class number to x2000. Since we will train a model consisting of one class, we set the Max_batches value to 6000. **We equalize max_batches(2000 x number of classes trained). But the minimum we can do is 6000, so if you have one, two and three classes, it should be 6000.**\n",
        "\n",
        "3. Then we change the value of the step to 80% or 90% of our max_batches value. I set the value of the step to 4800 which is 80% of 6000. **We make the values of the steps (80% of max_batches), (90% of max_batches).**\n",
        "\n",
        "4. We replace the classes values under the [yolo] heading with the number of classes we train.\n",
        "\n",
        "5. The Steps parameter is the number of iterations that the learning rate will be reduced to fit our model well. Finally, in our config file, we set the value of the class parameters to 3, which is our class number. We change the Filters parameters to (class + 5)x3. **In our case, this value is 18. We also equalize the filter's variables (number of classes to train + 5 )x3.**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oK1a9dCIyiuf"
      },
      "source": [
        "# upload the custom .cfg back to cloud VM from Google Drive\n",
        "\n",
        "!cp /content/drive/MyDrive/yolov4/yolov4-obj.cfg ./cfg"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8cInjxJm7GpZ"
      },
      "source": [
        "**-obj.names and obj.data**\n",
        "\n",
        "Let's create a file named obj.names in our folder named yolov3 and write the names of your objects that we will train the file with.\n",
        "\n",
        "E.G:\n",
        "```\n",
        "traffic sign\n",
        "traffic light\n",
        "```\n",
        "\n",
        "In the same folder, we create a file with the name obj.data and write the directory where we will save the number of objects we will train, the addresses of the files named train.txt, text.txt and obj.names that we will use while training, and the weights we find as a result of the training.\n",
        "\n",
        "E.G:\n",
        "```\n",
        "classes = 1\n",
        "train = data/train.txt\n",
        "valid = data/test.txt\n",
        "names = data/obj.names\n",
        "backup = /mydrive/yolov4/backup\n",
        "```\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gVQZjKcL95vl"
      },
      "source": [
        "upload the obj.names and obj.data files to cloud VM from Google Drive"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "c6-M5rFK7HN1"
      },
      "source": [
        "!cp /content/drive/MyDrive/yolov4/obj.names ./data\n",
        "!cp /content/drive/MyDrive/yolov4/obj.data  ./data"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IBr35ggE-AZq"
      },
      "source": [
        "#### **-Train and Test Files**\n",
        "\n",
        "\n",
        "**generate_train.py**\n",
        "\n",
        "\n",
        "\n",
        "```\n",
        "  import os\n",
        "  image_files = []\n",
        "  os.chdir(os.path.join(\"data\", \"obj\"))\n",
        "  for filename in os.listdir(os.getcwd()):\n",
        "      if filename.endswith(\".jpg\"):\n",
        "          image_files.append(\"data/obj/\" + filename)\n",
        "  os.chdir(\"..\")\n",
        "  with open(\"train.txt\", \"w\") as outfile:\n",
        "      for image in image_files:\n",
        "          outfile.write(image)\n",
        "          outfile.write(\"\\n\")\n",
        "      outfile.close()\n",
        "  os.chdir(\"..\")\n",
        "```\n",
        "\n",
        "**generate_test.py**\n",
        "\n",
        "\n",
        "\n",
        "```\n",
        "  import os\n",
        "\n",
        "  image_files = []\n",
        "  os.chdir(os.path.join(\"data\", \"test\"))\n",
        "  for filename in os.listdir(os.getcwd()):\n",
        "      if filename.endswith(\".jpg\"):\n",
        "          image_files.append(\"data/test/\" + filename)\n",
        "  os.chdir(\"..\")\n",
        "  with open(\"test.txt\", \"w\") as outfile:\n",
        "      for image in image_files:\n",
        "          outfile.write(image)\n",
        "          outfile.write(\"\\n\")\n",
        "      outfile.close()\n",
        "  os.chdir(\"..\")\n",
        "```\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "m5qJ748-TutK"
      },
      "source": [
        "upload the generate_train.py and generate_test.py script to cloud VM from Google Drive\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ec8OtGiW-Ety"
      },
      "source": [
        "!cp /content/drive/MyDrive/yolov4/generate_train.py ./\n",
        "!cp /content/drive/MyDrive/yolov4/generate_test.py ./"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bMF6d35sUC-4"
      },
      "source": [
        "!python generate_train.py\n",
        "!python generate_test.py"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GrKi1gUQUDeE"
      },
      "source": [
        "# verify that the newly generated train.txt and test.txt can be seen in our darknet/data folder\n",
        "!ls data/"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bZPKhQgqVFAF"
      },
      "source": [
        "### STEP 4: REDUCE THE WEIGHTS OF PRE-TRAINED CONVOLUTIONAL LAYERS\n",
        "\n",
        "In this step, we download the used deep learning layers weights for the pre-trained yolov3. We do not have to perform this step, but starting the training with these weights will help the model we train to work more accurately and shorten the training time."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ab3ofltAVGOu"
      },
      "source": [
        "!wget https://github.com/AlexeyAB/darknet/releases/download/darknet_yolo_v3_optimal/yolov4.conv.137"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MSm93uBkVTHV"
      },
      "source": [
        "### STEP 5: TRAINING\n",
        "All the necessary files are ready, we can start the training."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "db6QZ2HVWYFY"
      },
      "source": [
        "Training will begin with the next command.\n",
        "\n",
        "The duration of our training may vary depending on factors such as the number of photos in your data set, the quality of the photos, and the number of objects you train. Our loss value is important for the accuracy of our model. The lower our Loss value, the more accurate our model will work. We can run our model until the loss value stops decreasing and train the most accurate model possible according to our data set."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qVYYLkSmViFg"
      },
      "source": [
        "# train your custom detector! (uncomment %%capture below if you run into memory issues or your Colab is crashing)\n",
        "# %%capture\n",
        "!./darknet detector train data/obj.data cfg/yolov4-obj.cfg yolov4.conv.137 -dont_show -map"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MTv7nvWPWoL1"
      },
      "source": [
        "# the graph of our training.\n",
        "imShow('chart.png')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fIXX6trKW_Gm"
      },
      "source": [
        "If we don't like the weights, we can continue the training from where we left off."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pe0R7MNJW-lF"
      },
      "source": [
        "!./darknet detector train data/obj.data cfg/yolov4-obj.cfg /content/drive/MyDrive/yolov4/backup/yolov4-obj_last.weights -dont_show"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "s_1meAhSyd2d"
      },
      "source": [
        "### STEP 6: USE OUR TRAINED MODEL\n",
        "\n",
        "\n",
        "Our training is complete, now we can make recognition on the photos we want."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lyJzvhv4X48Z"
      },
      "source": [
        "Let's look at the average loss value and percent accuracy of our model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "630qDfB3ydff"
      },
      "source": [
        "!./darknet detector map data/obj.data cfg/yolov4-obj.cfg /content/drive/MyDrive/yolov4/backup/yolov4-obj_last.weights"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gG-MtCljyiwG"
      },
      "source": [
        "#### **Let's run our model**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1-j-hGJ2x-Le"
      },
      "source": [
        "Let's test our model for a single image"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KatbNMnfRoh0"
      },
      "source": [
        "# define helper functions\n",
        "def imShow(path): \n",
        "  import cv2\n",
        "  import matplotlib.pyplot as plt\n",
        "  %matplotlib inline\n",
        "\n",
        "  image = cv2.imread(path)\n",
        "  height, width = image.shape[:2]\n",
        "  resized_image = cv2.resize(image,(3*width, 3*height), interpolation = cv2.INTER_CUBIC)\n",
        "\n",
        "  fig = plt.gcf()\n",
        "  fig.set_size_inches(18, 10)\n",
        "  plt.axis(\"off\")\n",
        "  plt.imshow(cv2.cvtColor(resized_image, cv2.COLOR_BGR2RGB))\n",
        "  plt.show()\n",
        "\n",
        "# use this to upload files\n",
        "def upload():\n",
        "  from google.colab import files\n",
        "  uploaded = files.upload() \n",
        "  for name, data in uploaded.items():\n",
        "    with open(name, 'wb') as f:\n",
        "      f.write(data)\n",
        "      print ('saved file', name)\n",
        "\n",
        "# use this to download a file  \n",
        "def download(path):\n",
        "  from google.colab import files\n",
        "  files.download(path)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "miiXSHkkxrWT"
      },
      "source": [
        "cp /content/drive/MyDrive/yolov4/test_pred.zip ../"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8Cfz0TbvxrWT"
      },
      "source": [
        "%cd /content"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jpv9s-fdxrWU"
      },
      "source": [
        "!unzip /content/test_pred.zip "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kkAseV2exrWU"
      },
      "source": [
        "%cd /content/darknet/"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-lj-UAi4yp_c"
      },
      "source": [
        "# need to set our custom cfg to test mode \n",
        "%cd cfg\n",
        "!sed -i 's/batch=64/batch=1/' yolov4-obj.cfg\n",
        "!sed -i 's/subdivisions=16/subdivisions=1/' yolov4-obj.cfg\n",
        "%cd .."
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Yh1CnruZVk4w"
      },
      "source": [
        "To predict and see individual images"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rmOCrrdjysOR"
      },
      "source": [
        "# run your custom detector with this command (upload an image to your google drive to test, thresh flag sets accuracy that detection must be in order to show it)\n",
        "!./darknet detector test data/obj.data cfg/yolov4-obj.cfg /content/test_pred/510256_cfc_002219.jpg -ext_output -dont_show -out  result.json -thresh 0.3 \n",
        "imShow('predictions.jpg')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PrzCzhhwZGKG"
      },
      "source": [
        "### **STEP 7: PREDICTION WITH TEST DATASET**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "t4cZsCdlX6AE"
      },
      "source": [
        "cp /content/drive/MyDrive/yolov4/test_pred.zip ../"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jA2Fo4P_X6AF"
      },
      "source": [
        "%cd /content"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9bL6oTECX6AF"
      },
      "source": [
        "!unzip /content/test_pred.zip "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EDFFLAXUX6AG"
      },
      "source": [
        "%cd /content/darknet/"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "v1JoPtDGX6AG"
      },
      "source": [
        "# need to set our custom cfg to test mode \n",
        "%cd cfg\n",
        "!sed -i 's/batch=64/batch=1/' yolov4-obj.cfg\n",
        "!sed -i 's/subdivisions=16/subdivisions=1/' yolov4-obj.cfg\n",
        "%cd .."
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VgWUJSIKX6AH"
      },
      "source": [
        "!cp /content/drive/MyDrive/yolov4/backup/yolov4-obj_last.weights ../"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "K5ZaNViPX6AH"
      },
      "source": [
        "import glob\n",
        "import os\n",
        "image_path=\"../test_pred\"\n",
        "image_path_list = glob.glob(os.path.join(image_path, '*'))\n",
        "image_path_list.sort()\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-7xWcSZaX6AH"
      },
      "source": [
        "\n",
        "def detectionPredict(imageDir):\n",
        "    import glob\n",
        "    import os\n",
        "    import cv2\n",
        "    os.system(\"./darknet detector test data/obj.data cfg/yolov4-obj.cfg ../yolov4-obj_last.weights {} -thresh 0.3\".format(imageDir))\n",
        "\n",
        "  "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GQyzNWOvX6AI"
      },
      "source": [
        "#import torch.nn as nn\n",
        "#import torch.optim as optim\n",
        "from constant import *\n",
        "import tqdm\n",
        "import torch\n",
        "from preprocessing import tensorize_image, tensorize_mask, image_mask_check\n",
        "import cv2\n",
        "from train import *\n",
        "from PIL import Image\n",
        "\n",
        "\n",
        "\n",
        "for i in tqdm.tqdm(range(len(image_path_list))):\n",
        "    batch_test = image_path_list[i:i+1]\n",
        "    detectionPredict(batch_test[0])\n",
        "    img=cv2.imread(\"predictions.jpg\")\n",
        "    predict_name=batch_test[0]\n",
        "    predict_path=predict_name.replace('test_pred', 'predict_sign')\n",
        "    cv2.imwrite(predict_path,img.astype(np.uint8))\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XXWahUhkX6AI"
      },
      "source": [
        "!zip -r predict_sign.zip /content/predict_sign\n",
        "!cp predict_sign.zip /content/drive/MyDrive/predicts"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RX-UOg0-YBfU"
      },
      "source": [
        "### **STEP 8: Multi class prediction**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XvDACYmMVvjM"
      },
      "source": [
        "**Predict from freespace, line and sign models**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_WAABvvFLh5Q"
      },
      "source": [
        "cp /content/drive/MyDrive/yolov4/test_pred.zip ../"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HHTRHKPzu3gW"
      },
      "source": [
        "%cd /content"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zR7_0BpGeIrl"
      },
      "source": [
        "!unzip /content/test_pred.zip "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ts7JfnG2g_Cy"
      },
      "source": [
        "%cd /content/darknet/"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "K9USp054fwIw"
      },
      "source": [
        "# need to set our custom cfg to test mode \n",
        "%cd cfg\n",
        "!sed -i 's/batch=64/batch=1/' yolov4-obj.cfg\n",
        "!sed -i 's/subdivisions=16/subdivisions=1/' yolov4-obj.cfg\n",
        "%cd .."
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5GiFgH6jEs3R"
      },
      "source": [
        "!cp /content/drive/MyDrive/yolov4/backup/yolov4-obj_last.weights ../"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "deZsUdQMNsm_"
      },
      "source": [
        "import glob\n",
        "import os\n",
        "image_path=\"../test_pred\"\n",
        "image_path_list = glob.glob(os.path.join(image_path, '*'))\n",
        "image_path_list.sort()\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZmFKa5fSWJkS"
      },
      "source": [
        "\n",
        "def detectionPredict(imageDir):\n",
        "    import glob\n",
        "    import os\n",
        "    import cv2\n",
        "    os.system(\"./darknet detector test data/obj.data cfg/yolov4-obj.cfg ../yolov4-obj_last.weights {} -ext_output -dont_show -out result.json -thresh 0.3\".format(imageDir))\n",
        "\n",
        "  "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "glgDDvrOLOU2"
      },
      "source": [
        "#import torch.nn as nn\n",
        "#import torch.optim as optim\n",
        "from constant import *\n",
        "import tqdm\n",
        "import torch\n",
        "from preprocessing import tensorize_image, tensorize_mask, image_mask_check\n",
        "import cv2\n",
        "from train import *\n",
        "from PIL import Image\n",
        "\n",
        "\n",
        "\n",
        "model_freespace= torch.load('/content/drive/MyDrive/models/Unet_1.pt')\n",
        "\n",
        "model_line=torch.load('/content/drive/MyDrive/models/best_line_model.pt',map_location='cuda:0')\n",
        "model_freespace=model_freespace.eval()\n",
        "model_line=model_line.eval()\n",
        "input_shape=(224,224)\n",
        "cuda=True\n",
        "if cuda:\n",
        "    model_line = model_line.cuda()\n",
        "    model_freespace=model_freespace.cuda()\n",
        "\n",
        "\n",
        "for i in tqdm.tqdm(range(len(image_path_list))):\n",
        "    batch_test = image_path_list[i:i+1]\n",
        "    detectionPredict(batch_test[0])\n",
        "    img=cv2.imread(\"predictions.jpg\")\n",
        "\n",
        "    test_input_line = tensorize_image(batch_test, input_shape, cuda)\n",
        "    test_input_freespace=tensorize_image(batch_test, input_shape, cuda)\n",
        "\n",
        "    outs_freespace = model_freespace(test_input_freespace)\n",
        "    outs_line = model_line(test_input_line)\n",
        "\n",
        "    out_freespace=torch.argmax(outs_freespace,axis=1)\n",
        "    out_line=torch.argmax(outs_line,axis=1)\n",
        "\n",
        "    out_freespace_cpu = out_freespace.cpu()\n",
        "    out_line_cpu=out_line.cpu()\n",
        "\n",
        "    outputs_list_freespace=out_freespace_cpu.detach().numpy()\n",
        "    outputs_list_line=out_line_cpu.detach().numpy()\n",
        "\n",
        "    mask_freespace=np.squeeze(outputs_list_freespace,axis=0)\n",
        "    mask_line=np.squeeze(outputs_list_line,axis=0)\n",
        "\n",
        "    mask_uint8_line = mask_line.astype('uint8')\n",
        "    mask_uint8_freespace = mask_freespace.astype('uint8')\n",
        "    \n",
        "    mask_line= cv2.resize(mask_uint8_line, ((img.shape[1]), (img.shape[0])),interpolation=cv2.INTER_NEAREST)\n",
        "    mask_freespace= cv2.resize(mask_uint8_freespace, ((img.shape[1]), (img.shape[0])),interpolation=cv2.INTER_CUBIC)\n",
        "        \n",
        "\n",
        " \n",
        "    mask_ind   = mask_line == 1\n",
        "    mask_ind   = mask_freespace == 1\n",
        "    cpy_img  = img.copy()\n",
        "    \n",
        "    img[mask_freespace==1,:] = (255, 0, 125)\n",
        "\n",
        "\n",
        "    img[mask_line==1,:]=(0, 0, 255)\n",
        "    img[mask_line==2,:]=(38, 255, 255)\n",
        "    \n",
        "    \n",
        "    opac_image=(img/2+cpy_img/2).astype(np.uint8)\n",
        "    predict_name=batch_test[0]\n",
        "    predict_path=predict_name.replace('test_pred', 'full_predict')\n",
        "    cv2.imwrite(predict_path,opac_image.astype(np.uint8))\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jTrAoFyQPhB_"
      },
      "source": [
        "!zip -r predict_full.zip /content/full_predict\n",
        "!cp predict_full.zip /content/drive/MyDrive/predicts"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pSjhFJeTxTsw"
      },
      "source": [
        "### **STEP 9: MULTI CLASS DETECTION IN VIDEO DATA**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "b0qbo6GsxTBY"
      },
      "source": [
        "!./darknet detector demo data/obj.data cfg/yolov4-obj.cfg /content/drive/MyDrive/yolov4/backup/yolov4-obj_last.weights -dont_show /content/drive/MyDrive/video/videoplayback_3.mp4 -thresh 0.2 -i 0 -out_filename /content/drive/MyDrive/video/results3.avi"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GzPZVz6OmwkJ"
      },
      "source": [
        "import cv2\n",
        "# Opens the Video file\n",
        "cap = cv2.VideoCapture('/content/drive/MyDrive/video/results3.avi')\n",
        "i = 0\n",
        "while(cap.isOpened()):\n",
        "    ret, frame = cap.read()\n",
        "    if ret == False:\n",
        "        break\n",
        "    cv2.imwrite('frames/kang'+str(i)+'.jpg',frame)\n",
        "    i+=1\n",
        " \n",
        "cap.release()\n",
        "cv2.destroyAllWindows()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YtZDPJm_pe7n"
      },
      "source": [
        "#import torch.nn as nn\n",
        "#import torch.optim as optim\n",
        "import os\n",
        "from constant import *\n",
        "import glob\n",
        "import tqdm\n",
        "import torch\n",
        "import numpy as np\n",
        "from preprocessing import tensorize_image, tensorize_mask, image_mask_check\n",
        "import cv2\n",
        "from PIL import Image\n",
        "model_freespace= torch.load('/content/drive/MyDrive/models/Unet_1.pt')\n",
        "\n",
        "model_line=torch.load('/content/drive/MyDrive/models/best_line_model.pt',map_location='cuda:0')\n",
        "model_freespace=model_freespace.eval()\n",
        "model_line=model_line.eval()\n",
        "input_shape=(224,224)\n",
        "cuda=True\n",
        "if cuda:\n",
        "    model_line = model_line.cuda()\n",
        "    model_freespace=model_freespace.cuda()\n",
        "\n",
        "image_path=\"/content/frames\"\n",
        "image_path_list = glob.glob(os.path.join(image_path, '*'))\n",
        "image_path_list.sort()\n",
        "\n",
        "for i in tqdm.tqdm(range(len(image_path_list))):\n",
        "    batch_test = image_path_list[i:i+1]\n",
        "    img=cv2.imread(batch_test[0])\n",
        "\n",
        "    test_input_line = tensorize_image(batch_test, input_shape, cuda)\n",
        "    test_input_freespace=tensorize_image(batch_test, input_shape, cuda)\n",
        "\n",
        "    outs_freespace = model_freespace(test_input_freespace)\n",
        "    outs_line = model_line(test_input_line)\n",
        "\n",
        "    out_freespace=torch.argmax(outs_freespace,axis=1)\n",
        "    out_line=torch.argmax(outs_line,axis=1)\n",
        "\n",
        "    out_freespace_cpu = out_freespace.cpu()\n",
        "    out_line_cpu=out_line.cpu()\n",
        "\n",
        "    outputs_list_freespace=out_freespace_cpu.detach().numpy()\n",
        "    outputs_list_line=out_line_cpu.detach().numpy()\n",
        "\n",
        "    mask_freespace=np.squeeze(outputs_list_freespace,axis=0)\n",
        "    mask_line=np.squeeze(outputs_list_line,axis=0)\n",
        "\n",
        "    mask_uint8_line = mask_line.astype('uint8')\n",
        "    mask_uint8_freespace = mask_freespace.astype('uint8')\n",
        "\n",
        "    mask_line= cv2.resize(mask_uint8_line, ((img.shape[1]), (img.shape[0])),interpolation=cv2.INTER_NEAREST)\n",
        "    mask_freespace= cv2.resize(mask_uint8_freespace, ((img.shape[1]), (img.shape[0])),interpolation=cv2.INTER_CUBIC)\n",
        "\n",
        "\n",
        "\n",
        " \n",
        "    mask_ind   = mask_line == 1\n",
        "    mask_ind   = mask_freespace == 1\n",
        "    cpy_img  = img.copy()\n",
        "    \n",
        "    img[mask_freespace==1,:] = (255, 0, 125)\n",
        "\n",
        "\n",
        "    img[mask_line==1,:]=(0, 0, 255)\n",
        "    img[mask_line==2,:]=(38, 255, 255)\n",
        "    \n",
        "    \n",
        "    opac_image=(img/2+cpy_img/2).astype(np.uint8)\n",
        "    predict_name=batch_test[0]\n",
        "    predict_path=predict_name.replace('frames', 'full_predict')\n",
        "    cv2.imwrite(predict_path,opac_image.astype(np.uint8))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "x_nZ2qN7wu5W"
      },
      "source": [
        "import cv2\n",
        "import numpy as np\n",
        "import os\n",
        "from os.path import isfile, join\n",
        "from natsort import natsorted\n",
        "\n",
        "pathIn= '/content/frames/'\n",
        "pathOut = '/content/predict_video/video24.avi'\n",
        "fps = 24\n",
        "frame_array = []\n",
        "files = [f for f in os.listdir(pathIn) if isfile(join(pathIn, f))]\n",
        "#for sorting the file names properly\n",
        "files = natsorted(files)\n",
        "for i in range(len(files)):\n",
        "    filename=pathIn + files[i]\n",
        "    #reading each files\n",
        "    img = cv2.imread(filename)\n",
        "    height, width, layers = img.shape\n",
        "    size = (width,height)\n",
        "    \n",
        "    #inserting the frames into an image array\n",
        "    frame_array.append(img)\n",
        "out = cv2.VideoWriter(pathOut,cv2.VideoWriter_fourcc(*'DIVX'), fps, size)\n",
        "for i in range(len(frame_array)):\n",
        "    # writing to a image array\n",
        "    out.write(frame_array[i])\n",
        "out.release()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Kbo8zKxUz5tR"
      },
      "source": [
        "!cp /content/predict_video/video24.avi /content/drive/MyDrive/video"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sagy89yyHb4g"
      },
      "source": [
        "# CLASSIFICATION"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uKqPGaQSggmc"
      },
      "source": [
        "# upload the custom .cfg back to cloud VM from Google Drive\n",
        "\n",
        "!cp /content/drive/MyDrive/yolov4/yolov4-obj.cfg ./cfg"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "a7N1Kt1G90om"
      },
      "source": [
        "!cp /content/drive/MyDrive/yolov4/obj.names ./data\n",
        "!cp /content/drive/MyDrive/yolov4/obj.data  ./data"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uyozOMXd90on"
      },
      "source": [
        "!cp /content/drive/MyDrive/yolov4/generate_train.py ./\n",
        "!cp /content/drive/MyDrive/yolov4/generate_test.py ./"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IDRXBf2LdxIj"
      },
      "source": [
        "!cp /content/drive/MyDrive/yolov4/backup/yolov4-obj_last.weights ../"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gBZQyoL0dxIj"
      },
      "source": [
        "cp /content/drive/MyDrive/yolov4/test_pred.zip ../"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cM-BsGi4dxIk"
      },
      "source": [
        "%cd /content\n",
        "!unzip /content/test_pred.zip "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xXpYJh1UdxIl"
      },
      "source": [
        "%cd /content/darknet/"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jaFPuE4edxIl"
      },
      "source": [
        "# need to set our custom cfg to test mode \n",
        "%cd cfg\n",
        "!sed -i 's/batch=64/batch=1/' yolov4-obj.cfg\n",
        "!sed -i 's/subdivisions=16/subdivisions=1/' yolov4-obj.cfg\n",
        "%cd .."
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2y9Gsv_pdxIl"
      },
      "source": [
        "#### STEP1: CROP_SIGN"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pN600lsbdxIl"
      },
      "source": [
        "import json\n",
        "import cv2\n",
        "\n",
        "def crop_sign():\n",
        "  \n",
        "  for f in glob.glob(\"/content/crop_image/*\"):\n",
        "    os.remove(f)\n",
        "  positions=[]\n",
        "  json_file = open('/content/darknet/result.json', 'r')#file reading process\n",
        "  json_dict=json.load(json_file)#Contents of json file converted to dict data type\n",
        "  \n",
        "  img= cv2.imread(json_dict[0][\"filename\"])\n",
        "  for i,obj in enumerate(json_dict[0][\"objects\"]):\n",
        "    if obj['class_id'] ==0:\n",
        "\n",
        "      center_x=img.shape[1]*obj[\"relative_coordinates\"]['center_x']\n",
        "      center_y=img.shape[0]*obj[\"relative_coordinates\"]['center_y']\n",
        "      width=img.shape[1]*obj[\"relative_coordinates\"]['width']\n",
        "      height=img.shape[0]*obj[\"relative_coordinates\"]['height']\n",
        "\n",
        "      #x_center=int(xmin + width()/2)\n",
        "      #y_center=int(ymin + height()/2)\n",
        "\n",
        "      new_width=(img.shape[1]*obj[\"relative_coordinates\"]['width'])/2\n",
        "      new_height=(img.shape[0]*obj[\"relative_coordinates\"]['height'])/2\n",
        "\n",
        "      x_min=abs(center_x-new_width)\n",
        "      y_min=abs(center_y-new_height)\n",
        "\n",
        "      #width=int(xmax-xmin)\n",
        "      #height=int(ymax-ymin)\n",
        "\n",
        "      x_max=width+x_min\n",
        "      y_max=height+y_min\n",
        "\n",
        "      w=int(width)\n",
        "      h=int(height)\n",
        "\n",
        "      positions.append([int(x_min), int(y_min), int(x_max),int(y_max)])\n",
        "      crop_img = img[int(y_min):int(y_min)+h,int(x_min):int(x_min)+w]\n",
        "      ci_path=json_dict[0][\"filename\"].replace('test_pred','crop_image')\n",
        "      cv2.imwrite(ci_path[:-4]+\"-\"+str(i)+\".jpg\",crop_img)\n",
        "  return positions"
      ],
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "s4luT0g7dxIl"
      },
      "source": [
        "  import glob\n",
        "  import os\n",
        "  for f in glob.glob(\"/content/full_predict/*\"):\n",
        "    os.remove(f)"
      ],
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bQZDTg4ldxIl"
      },
      "source": [
        "import os\n",
        "import cv2\n",
        "from PIL import Image\n",
        "import numpy as np\n",
        "from keras import models\n",
        "import glob\n",
        "def class_pred():\n",
        "\n",
        "  for f in glob.glob(\"/content/meta_image/*\"):\n",
        "    os.remove(f)\n",
        "\n",
        "  crop_img=os.listdir('/content/crop_image')\n",
        "  \n",
        "  for f in crop_img:\n",
        "    if f.startswith(\".\"):\n",
        "      crop_img.remove(f)\n",
        "  \n",
        "  crop_img.sort()\n",
        "  data=[]\n",
        "  for i in crop_img:\n",
        "    image=cv2.imread(\"/content/crop_image/\"+i)\n",
        "    imageRGB = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
        "    image_fromarray = Image.fromarray(imageRGB, 'RGB')\n",
        "    resize_image = image_fromarray.resize((30, 30))\n",
        "    data.append(np.array(resize_image))\n",
        "\n",
        "  X_test = np.array(data)\n",
        "  X_test = X_test/255\n",
        "  model=models.load_model('/content/drive/MyDrive/classification/sign_ford_model.h5')\n",
        "  y = model.predict(X_test)\n",
        "  pred=np.argmax(y,axis=1)\n",
        "\n",
        "  for n,pr in enumerate(pred):\n",
        "    meta_path='/content/drive/MyDrive/classification/Meta/'\n",
        "    meta_image_path=meta_path+str(pr)+'.png'\n",
        "    meta_image=cv2.imread(meta_image_path, cv2.IMREAD_UNCHANGED)\n",
        "    cv2.imwrite('/content/meta_image/'+str(n)+'.jpg',meta_image)\n",
        "\n",
        "  \n"
      ],
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bdIODFiBdxIl"
      },
      "source": [
        "#  FINAL\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oUR5-8MreS9A"
      },
      "source": [
        "if you want test images on video images"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yt-yRQXMdMZ5"
      },
      "source": [
        "import cv2\n",
        "# Opens the Video file\n",
        "cap = cv2.VideoCapture('/content/drive/MyDrive/video/results3.avi')\n",
        "i = 0\n",
        "while(cap.isOpened()):\n",
        "    ret, frame = cap.read()\n",
        "    if ret == False:\n",
        "        break\n",
        "    cv2.imwrite('frames/kang'+str(i)+'.jpg',frame)\n",
        "    i+=1\n",
        " \n",
        "cap.release()\n",
        "cv2.destroyAllWindows()"
      ],
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wOKGeCj_ec4t"
      },
      "source": [
        "If you want, you can take the images directly from the folder and test them."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5GvCQ8nidxIm"
      },
      "source": [
        "import glob\n",
        "import os\n",
        "image_path=\"../test_pred\"\n",
        "image_path_list = glob.glob(os.path.join(image_path, '*'))\n",
        "image_path_list.sort()\n"
      ],
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8O3q3vczdxIm"
      },
      "source": [
        "\n",
        "def detectionPredict(imageDir):\n",
        "    import glob\n",
        "    import os\n",
        "    import cv2\n",
        "    os.system(\"./darknet detector test data/obj.data cfg/yolov4-obj.cfg ../yolov4-obj_last.weights {} -ext_output -dont_show -out result.json -thresh 0.6 \".format(imageDir))\n",
        "\n",
        "  "
      ],
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "n-wZnXtVdxIm"
      },
      "source": [
        "#import torch.nn as nn\n",
        "#import torch.optim as optim\n",
        "from constant import *\n",
        "import tqdm\n",
        "import torch\n",
        "from preprocessing import tensorize_image, tensorize_mask, image_mask_check\n",
        "import cv2\n",
        "from train import *\n",
        "from PIL import Image\n",
        "\n",
        "\n",
        "\n",
        "model_freespace= torch.load('/content/drive/MyDrive/models/Unet_1.pt')\n",
        "\n",
        "model_line=torch.load('/content/drive/MyDrive/models/best_line_model.pt',map_location='cuda:0')\n",
        "model_freespace=model_freespace.eval()\n",
        "model_line=model_line.eval()\n",
        "input_shape=(224,224)\n",
        "cuda=True\n",
        "if cuda:\n",
        "    model_line = model_line.cuda()\n",
        "    model_freespace=model_freespace.cuda()\n",
        "\n",
        "\n",
        "for i in tqdm.tqdm(range(len(image_path_list))):\n",
        "    batch_test = image_path_list[i:i+1]\n",
        "    detectionPredict(batch_test[0])\n",
        "    img=cv2.imread(\"predictions.jpg\")\n",
        "    positions=crop_sign()\n",
        "    if not len(positions) == 0:\n",
        "      class_pred()\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "    test_input_line = tensorize_image(batch_test, input_shape, cuda)\n",
        "    test_input_freespace=tensorize_image(batch_test, input_shape, cuda)\n",
        "\n",
        "    outs_freespace = model_freespace(test_input_freespace)\n",
        "    outs_line = model_line(test_input_line)\n",
        "\n",
        "    out_freespace=torch.argmax(outs_freespace,axis=1)\n",
        "    out_line=torch.argmax(outs_line,axis=1)\n",
        "\n",
        "    out_freespace_cpu = out_freespace.cpu()\n",
        "    out_line_cpu=out_line.cpu()\n",
        "\n",
        "    outputs_list_freespace=out_freespace_cpu.detach().numpy()\n",
        "    outputs_list_line=out_line_cpu.detach().numpy()\n",
        "\n",
        "    mask_freespace=np.squeeze(outputs_list_freespace,axis=0)\n",
        "    mask_line=np.squeeze(outputs_list_line,axis=0)\n",
        "\n",
        "    mask_uint8_line = mask_line.astype('uint8')\n",
        "    mask_uint8_freespace = mask_freespace.astype('uint8')\n",
        "    \n",
        "    mask_line= cv2.resize(mask_uint8_line, ((img.shape[1]), (img.shape[0])),interpolation=cv2.INTER_NEAREST)\n",
        "    mask_freespace= cv2.resize(mask_uint8_freespace, ((img.shape[1]), (img.shape[0])),interpolation=cv2.INTER_CUBIC)\n",
        "        \n",
        "\n",
        " \n",
        "    mask_ind   = mask_line == 1\n",
        "    mask_ind   = mask_freespace == 1\n",
        "    cpy_img  = img.copy()\n",
        "    \n",
        "    img[mask_freespace==1,:] = (255, 0, 125)\n",
        "\n",
        "\n",
        "    img[mask_line==1,:]=(0, 0, 255)\n",
        "    img[mask_line==2,:]=(38, 255, 255)\n",
        "    \n",
        "    \n",
        "    opac_image=(img/2+cpy_img/2).astype(np.uint8)\n",
        "\n",
        "    if not len(positions) == 0:\n",
        "      for i,pos in enumerate(positions):\n",
        "        x_meta=cv2.imread('/content/meta_image/'+str(i)+'.jpg', cv2.IMREAD_UNCHANGED)\n",
        "        x_len = int(pos[2]-pos[0])\n",
        "        y_len = int(pos[3]-pos[1])\n",
        "\n",
        "            \n",
        "        res_perc = int(min(x_len, y_len)*70/100)\n",
        "\n",
        "        if res_perc >= 40:\n",
        "          res_perc = 40\n",
        "\n",
        "        x_meta = cv2.resize(x_meta, (res_perc, res_perc))\n",
        "            \n",
        "              \n",
        "            #x = pos[2] - res_perc\n",
        "            #y = pos[3] - res_perc\n",
        "        x = pos[0]+2\n",
        "        y = pos[1]+2\n",
        "        opac_image[y:y+x_meta.shape[0],x:x+x_meta.shape[1]] = x_meta\n",
        "        '''\n",
        "        y1, y2 = y, y + x_meta.shape[0]\n",
        "        x1, x2 = x, x + x_meta.shape[1]\n",
        "\n",
        "        alpha_s = x_meta[:, :, 2] / 255.0\n",
        "        alpha_l = 1.0 - alpha_s\n",
        "\n",
        "        for c in range(0, 3):\n",
        "          opac_image[y1:y2, x1:x2, c] = (alpha_s * x_meta[:, :, c] +\n",
        "                                         alpha_l * opac_image[y1:y2, x1:x2, c])\n",
        "\n",
        "         '''\n",
        "       \n",
        "    predict_path=batch_test[0].replace('test_pred', 'full_predict')\n",
        "    cv2.imwrite(predict_path,opac_image.astype(np.uint8))\n",
        "\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WThvFq6KdxIm"
      },
      "source": [
        "!zip -r predict_full.zip /content/full_predict\n",
        "!cp predict_full.zip /content/drive/MyDrive/predicts"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Q7FV7LvtdUgZ"
      },
      "source": [
        "import cv2\n",
        "import numpy as np\n",
        "import os\n",
        "from os.path import isfile, join\n",
        "from natsort import natsorted\n",
        "\n",
        "pathIn= '/content/frames/'\n",
        "pathOut = '/content/predict_video/video24.avi'\n",
        "fps = 24\n",
        "frame_array = []\n",
        "files = [f for f in os.listdir(pathIn) if isfile(join(pathIn, f))]\n",
        "#for sorting the file names properly\n",
        "files = natsorted(files)\n",
        "for i in range(len(files)):\n",
        "    filename=pathIn + files[i]\n",
        "    #reading each files\n",
        "    img = cv2.imread(filename)\n",
        "    height, width, layers = img.shape\n",
        "    size = (width,height)\n",
        "    \n",
        "    #inserting the frames into an image array\n",
        "    frame_array.append(img)\n",
        "out = cv2.VideoWriter(pathOut,cv2.VideoWriter_fourcc(*'DIVX'), fps, size)\n",
        "for i in range(len(frame_array)):\n",
        "    # writing to a image array\n",
        "    out.write(frame_array[i])\n",
        "out.release()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EUkTsAWOdaIW"
      },
      "source": [
        "!cp /content/predict_video/video24.avi /content/drive/MyDrive/video"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}